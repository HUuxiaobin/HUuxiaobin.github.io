<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Xiaobin Hu</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Xiaobin Hu (胡晓彬)</name>
              </p>
              <p>I am a fourth Ph.D Candidate at <a href="https://www.tum.de/">Technische Universität München, Germany </a> CAMP (IBBM) Group, supervised by Prof. Bjoern Menze.
                 Before that, I obtained my master at <a href="https://www.hnu.edu.cn/index.htm">Hunan University </a>, where I studied the physics-based FEM probability analysis and optimization.
              </p>
              <p>
               As a <B> first </B> or <B> corrspoding </B> author, I have published over <B> 12 </B> papers on top-tier conferences and journals, such as ICCV, ECCV, TPAMI, MICCAI, JBHI, EJNM etc.
              </p>
		Email: <a href="xbhunanu@gmail.com">xbhunanu [at] gmail.com</a></p>
           </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="./files/photo.jpg"><img style="width:100%;max-width:100%;border-radius:100%" alt="Avatar" src="./files/photo.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
	</tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
		    
	My research interests are mainly at image restoration and neural architecture search.
	Currently, I investigate on how to solve <B> the real-world low-quality image restoration </B> problems. In addition, I also have some experience on the following research topics:</p>
	<ul>
	<li>Image restoration inculding super-resolution and deblurring tasks</li>
	<li>Neural architecture search</li>	
	<li>3D face and related Tasks</li>
	<li>Image to image translation</li>
	<li>Uncertainty analysis and interpretation </li>
	<li>Segmentation, detection and classification</li>
	<li>Domain adaptation</li>
	
<!-- 	<li>GAN Priors</li> -->
<!-- 	<li>Image Inpainting and Completion</li> -->

	</ul>
	  	   
      <p style="text-align:center">
			<a href="mailto:xbhunanu@gmail.com"><i class="fa fa-envelope" style="font-size:20px" target="_blank"></i>&nbsp; Email</a> &nbsp;/&nbsp;
			<a href="https://scholar.google.de/citations?user=3lMuodUAAAAJ&hl=en" target="_blank"><i class="ai ai-google-scholar-square ai-3x" style="font-size:20px"></i>&nbsp; Google Scholar</a> &nbsp;/&nbsp;
			<a href="https://github.com/HUuxiaobin" target="_blank"><i class="fa fa-github" style="font-size:20px"></i>&nbsp; Github</a> &nbsp;/&nbsp;
<!-- 			<a href="https://twitter.com/sekunde_" target="_blank"><i class="fa fa-twitter" style="font-size:20px"></i>&nbsp; Twitter</a> &nbsp;/&nbsp;
			<a href="https://www.linkedin.com/in/ji-hou-3b64a2a0/" target="_blank"><i class="fa fa-linkedin" style="font-size:20px"></i>&nbsp; Linkedin</a>  -->
			</p>	
	         

              <h4>Selected Publications</h4>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>	
	
<!-- ###---------------------------------------------------------------paper 1 TPAMI  -->
	<tr>
            <td style="padding:20px;width:40%;vertical-align:middle">
              <img src="files/tpami_3d_priors.JPG" alt="pri3d" width="300" style="border-radius: 15px">
            </td>
            <td width="75%" valign="middle">
<!--               <a href="https://arxiv.org/pdf/2104.11225.pdf"> -->
                <papertitle>Face Restoration via Plug-and-Play 3D Facial Priors</papertitle>
<!--               </a> -->
              <br>
              <strong>Xiaobin Hu</strong>,
		    Wenqi Ren, 
		    Jiaolong Yang, 
		    Xiaochun Cao, 
		    David Wipf, 
		    Bjoern Menze, 
		    Xin Tong, 
		     Hongbin Zha,    
<!--               <a href="http://niessnerlab.org/members/matthias_niessner/profile.html">Matthias Nießner</a> -->
              <br>
		    <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2021 </em>
              <br>
<!--               <a href="https://arxiv.org/pdf/2104.11225.pdf">paper</a> /
              <a href="https://www.youtube.com/watch?v=l0JxnpbaN38">video</a> /
              <a href="data/pri3d.txt">bibtex</a> /
	      <a href='https://github.com/Sekunde/Pri3D'>code</a> -->
		paper /
              video /
              bibtex /
	      code
              <p> Existing face restoration algorithms only employ 2D priors without considering high dimensional information (3D). The 3D morphable facial priors are the main novelty of this work and are completely different from recently related 2D prior works</p>
            </td>
          </tr>
		
<!-- %%%------------------------------------------------------paper line 2 ICCV-->
		
		<tr>
            <td style="padding:20px;width:40%;vertical-align:middle">
              <img src="files/nas_deblurring.JPG" alt="pri3d" width="300" style="border-radius: 15px">
            </td>
            <td width="75%" valign="middle">
<!--               <a href="https://arxiv.org/pdf/2104.11225.pdf"> -->
                <papertitle>Pyramid Architecture Search for Real-Time Image Deblurring</papertitle>
<!--               </a> -->
              <br>
              <strong>Xiaobin Hu</strong>,
		 Wenqi Ren,
                 Kaicheng Yu,
		Kaihao Zhang,
		Xiaochun Cao,
		 Wei Liu,
		 Bjoern Menze,    
<!--               <a href="http://niessnerlab.org/members/matthias_niessner/profile.html">Matthias Nießner</a> -->
              <br>
		    <em>International Conference on Computer Vision (ICCV), 2021, Montreal, Canada </em>
              <br>
<!--               <a href="https://arxiv.org/pdf/2104.11225.pdf">paper</a> /
              <a href="https://www.youtube.com/watch?v=l0JxnpbaN38">video</a> /
              <a href="data/pri3d.txt">bibtex</a> /
	      <a href='https://github.com/Sekunde/Pri3D'>code</a> -->
		paper /
              video /
              bibtex /
	      code
              <p> we propose a novel deblurring method, dubbed PyNAS, towards automatically designing hyper-parameters including the scales, patches, and standard cell operators. Our primary contribution is a real-time deblurring algorithm (around 58 fps) for 720p images while achieves state-of-the-art deblurring performance on the GoPro and Video Deblurring datasets.</p>
            </td>
          </tr>
		
		
<!-- %%%------------------------------------------------------paper line  TIP-->
		
		<tr>
            <td style="padding:20px;width:40%;vertical-align:middle">
              <img src="files/TIP_2021.JPG" alt="pri3d" width="300" style="border-radius: 15px">
            </td>
            <td width="75%" valign="middle">
              <a href="https://ieeexplore.ieee.org/document/9426447">
                <papertitle>SRGAT: Single Image Super-Resolution With Graph Attention Network</papertitle>
              </a>
              <br>
		    Yanyang Yan,
		    Wenqi Ren,
              <strong> Xiaobin Hu</strong>,
		    Kun Li,
                 Haifeng Shen,
		Xiaochun Cao,   
<!--               <a href="http://niessnerlab.org/members/matthias_niessner/profile.html">Matthias Nießner</a> -->
              <br>
		    <em> IEEE Transactions on Image Processing (TIP), 2021 </em>
              <br>
              <a href="https://ieeexplore.ieee.org/document/9426447">paper</a> /
<!--               <a href="https://www.youtube.com/watch?v=l0JxnpbaN38">video</a> /
              <a href="data/pri3d.txt">bibtex</a> /
	      <a href='https://github.com/Sekunde/Pri3D'>code</a> -->
<!-- 		paper / -->
              video /
              bibtex /
	      code
              <p> we propose a novel deblurring method, dubbed PyNAS, towards automatically designing hyper-parameters including the scales, patches, and standard cell operators. Our primary contribution is a real-time deblurring algorithm (around 58 fps) for 720p images while achieves state-of-the-art deblurring performance on the GoPro and Video Deblurring datasets.</p>
            </td>
          </tr>		
		
<!-- ###----------------------------------------------------------------paper line ECCV-->
		
		<tr>
            <td style="padding:20px;width:40%;vertical-align:middle">
              <img src="files/3d_priors_eccv.JPG" alt="pri3d" width="300" style="border-radius: 15px">
            </td>
            <td width="75%" valign="middle">
              <a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123490732.pdf">
                <papertitle>Face Super-Resolution Guided by 3D Facial Priors</papertitle>
              </a>
              <br>
              <strong>Xiaobin Hu</strong>,
		 Wenqi Ren,
                 John LaMaster,
		Xiaochun Cao,
		Xiaoming Li,
		 Zechao Li,
		 Bjoern Menze,    
		 Wei Liu,   
<!--               <a href="http://niessnerlab.org/members/matthias_niessner/profile.html">Matthias Nießner</a> -->
              <br>
		    <em>European Conference on Computer Vision (ECCV), 2020, </em>
              <br>
		    <font color="red">(Spotlight Presentation)</font>
	      <br>
               <a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123490732.pdf">paper</a> /
              video /
              <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:7O_TKmvpuxQJ:scholar.google.com/&output=citation&scisdr=CgXSEHgOENLesYiJAF8:AAGBfm0AAAAAYQ-PGF9QmYd8hwLFmS-AJYsXhdOF3c0D&scisig=AAGBfm0AAAAAYQ-PGPibfsXerjWGa5KI5iGr_9MaW83U&scisf=4&ct=citation&cd=-1&hl=zh-CN">bibtex</a> /
	      <a href="https://github.com/HUuxiaobin/Face-Super-Resolution-Guided-by-3D-Facial-Priors">code</a> 
<!-- 		paper /
              video /
              bibtex /
	      code -->
              <p> In this paper, we propose a novel face super resolution method that explicitly incorporates 3D facial priors which grasp the sharp facial structures. Our work is the first to explore 3D morphable knowledge based on the fusion of parametric descriptions of face attributes (e.g., identity, facial expression, texture, illumination, and face pose) </p>
            </td>
          </tr>	
		


        </tbody></table>
        
       <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Teaching</heading>
            </td>
          </tr>
        </tbody></table>
        
        <table width="100%" align="center" border="0" cellpadding="20">
            <tbody>
              <tr>
		<td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/teaching.png" width="160" style="border-radius:15px">
                </td>
                <td width="75%" valign="center" style="line-height:30px;">
                   <a target="_blank" href="https://www.3dunderstanding.org/teaching.html">Teaching
                    Assistant, Seminar for 3D Machine Learning  - Summer 2021</a>
		  <br>
                  <a target="_blank" href="https://dvl.in.tum.de/teaching/adl4cv-ws19/">Teaching
                    Assistant, Advanced Deep Learning for Computer Vision - Winter 2019/20</a>
                
                  <a target="_blank" href="https://dvl.in.tum.de/teaching/i2dl-ss18/">Teaching
                    Assistant, Introdcution to Deep Learning - Summer 2018</a>
			<br>
                  <a target="_blank" href="https://vision.cs.tum.edu/teaching/ws2017/dl4cv">Teaching
                    Assistant, Deep Learning for Computer Vision - Winter 2017/18</a>
                </td>
              </tr>
            </tbody>
          </table>
        
        
        
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tbody><tr>
        <td>
        <br>
        <p align="right"><font size="2">
      Credits: <a href="https://people.eecs.berkeley.edu/~barron/" target="_blank">Jon Barron</a>
          </font>
        </p>
        </td>
      </tr>
      </tbody></table>
	      

</body>

</html>
